{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The project as described on Kaggle\n",
    "\n",
    "You are provided hourly rental data spanning two years. For this competition, the training set is comprised of the first 19 days of each month, while the test set is the 20th to the end of the month. You must predict the total count of bikes rented during each hour covered by the test set, using only information available prior to the rental period.\n",
    "\n",
    "\n",
    "### Data Fields\n",
    "Field 0 contained the timestamp, fields 1 ... 8 were used for training. Field 11 for labeling/prediction. \n",
    "\n",
    "0 - datetime - hourly date + timestamp  \n",
    "\n",
    "1 - season -  1 = spring, 2 = summer, 3 = fall, 4 = winter \n",
    "\n",
    "2 - holiday - whether the day is considered a holiday \n",
    "\n",
    "3 - workingday - whether the day is neither a weekend nor holiday \n",
    "\n",
    "4 - weather - 1 = Clear, Few clouds, Partly cloudy, Partly cloudy, 2 = Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist, 3 = Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds, 4 = Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \n",
    "\n",
    "5 - temp - temperature in Celsius\n",
    "\n",
    "6 - atemp - \"feels like\" temperature in Celsius\n",
    "\n",
    "7 - humidity - relative humidity\n",
    "\n",
    "8 - windspeed - wind speed\n",
    "\n",
    "9 - casual - number of non-registered user rentals initiated\n",
    "\n",
    "10 - registered - number of registered user rentals initiated\n",
    "\n",
    "11 - count - number of total rentals\n",
    "\n",
    "### General ideas\n",
    "\n",
    "For this project I implemented a very simple version of a self-organizing map. It is an unsupervised learning method consisting of a 2D (here square) map of nodes which classify similar input vectors. Also, close nodes ('neighborhood') should represent close input vectors.\n",
    "\n",
    "An unsupervised algorithm doesn't provide predictions of actual outputs from the start. I addressed the need of a predicted output by labeling a node with the average of all its members (which resembles k-nearest neighbors.) A different approach could be to train a supervised method on all members of a given node.\n",
    "\n",
    "### File structure\n",
    "Files accessed by this notebook are under test, e.g., test/test.csv . Files accessed by the training notebook are under train/ . Some files are duplicated for clarity. Files like 'nodes.csv' which are shared by both notebooks are in the main directory . .\n",
    "\n",
    "### Implementation comments\n",
    "\n",
    "The training data was normalized (large values in the input data would dominate the distance function between nodes and inputs and skew the training) and shuffled (to avoid getting stuck in local minima.)\n",
    "\n",
    "The self-organizing map gets initialized by providing the (square) number of nodes and the training data. Each node gets initialized with a different input vector from the training data.\n",
    "\n",
    "Training one input vector consists of finding the node with the smallest Euclidean distance from the input vector and updating the node and its surrounding nodes (neighborhood) by the difference between the node and the input mulitplied by the learning rate. Neighborhoods are squares and each node is updated in this implementation with the same weight. One training cycle consists of training each input once. The total number of training cycles can be chosen freely. Over the course of the training the learning rate and size of the neighborhood get reduced in a linear fashion (other functions are possible, e.g., exp(-x).) This will stabilize the model toward the end of the training.\n",
    "\n",
    "After the full training each node gets labeled with the average of its known training outputs. These labels are employed to predict the outputs for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "[   4.            1.            1.            4.           41.\n",
      "   45.45500183  100.           56.99689865]\n",
      "[ 1.          0.          0.          1.          0.81999999  0.75999999\n",
      "  0.          0.        ]\n",
      "labeling April data: \n",
      "labeling 10am data: \n",
      "labeling 6pm data: \n",
      "labeling all data: \n",
      "node labels: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['random', 'test']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEACAYAAACuzv3DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRgEAAAAAAAAAAAAAAAAAAAAAAIDj1f8DhFaO42O2PgMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f420a6c9910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/87lNJaVOQkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f420a96ccd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import genfromtxt, savetxt, maximum, minimum\n",
    "from numpy.linalg import norm\n",
    "import random, math, pickle\n",
    "import matplotlib.pyplot\n",
    "import numpy.random\n",
    "\n",
    "# configure matplotlib to show figures embedded in the notebook\n",
    "%pylab inline\n",
    "\n",
    "#self-organizing map, assumed to be square, initialized with normalized data\n",
    "class SOM :\n",
    "    #initializes the nodes with normalized data, not random weights\n",
    "    def __init__(self, nr_nodes, data) :\n",
    "        #save length of one side of the map\n",
    "        self.one_side = int(math.sqrt(nr_nodes) + 0.5)\n",
    "        if self.one_side**2 != nr_nodes:\n",
    "            raise ValueError('nr_nodes was not a perfect square')\n",
    "        self.nodes = data[0::len(data)/nr_nodes][:nr_nodes]\n",
    "            \n",
    "    #save nodes to file\n",
    "    def save_nodes(self, location) :\n",
    "        pickle.dump(self.nodes, open(location, 'w'))\n",
    "    \n",
    "    #load nodes from file\n",
    "    def load_nodes(self, location) :\n",
    "        self.nodes = pickle.load(open(location, 'r'))\n",
    "                    \n",
    "    \n",
    "    #returns the node with the closest Euclidian distance to a given input vector\n",
    "    def find_winning_node(self, vector):\n",
    "        min_value = norm(vector-self.nodes[0])\n",
    "        min_count = 0\n",
    "        for count in range(len(self.nodes)) :\n",
    "            if(norm(vector-self.nodes[count]) < min_value) :\n",
    "                min_value = norm(vector-self.nodes[count])\n",
    "                min_count = count\n",
    "        return min_count\n",
    "    \n",
    "    #update the neighborhood around the winning node\n",
    "    #here we use a square neighborhood with the same weight to all updates inside\n",
    "    def update_neighborhood(self, vector, winner, distance, learning_rate):\n",
    "        #determine neighborhood - avoid leaving the map (don't go over borders)\n",
    "        x = winner/self.one_side\n",
    "        y = winner%self.one_side\n",
    "        left = max(0,y-distance)\n",
    "        right = min(self.one_side,y+distance+1)\n",
    "        top = max(0,x-distance)\n",
    "        bottom = min(self.one_side,x+distance+1)\n",
    "        #update neighborhood\n",
    "        for i in range(left,right):\n",
    "            for j in range(top,bottom):\n",
    "                k = self.one_side*j+i\n",
    "                self.nodes[k] += learning_rate * (vector - self.nodes[k])\n",
    "\n",
    "    #train each vector once\n",
    "    def train_one_cycle(self, data, distance, learning_rate):\n",
    "        node_count = [0]*len(self.nodes)\n",
    "        for data_point in data :\n",
    "            winner = self.find_winning_node(data_point)\n",
    "            node_count[winner] += 1\n",
    "            self.update_neighborhood(data_point, winner, distance, learning_rate)\n",
    "        #show distribution of training vectors over nodes as a heatmap\n",
    "        data = node_count\n",
    "        heatmap = matplotlib.pyplot.pcolor(numpy.reshape( data, (self.one_side, self.one_side)), cmap=plt.cm.Blues)\n",
    "        matplotlib.pyplot.show()\n",
    "        matplotlib.pyplot.gca().invert_yaxis()\n",
    "\n",
    "    #full training\n",
    "    def train(self, data, nr_steps, distance, learning_rate):\n",
    "        for i in range(0, nr_steps):\n",
    "            #update distance and learning rate as necessary\n",
    "            current_distance = distance - distance * i / nr_steps\n",
    "            current_learning_rate = learning_rate - learning_rate * i / nr_steps\n",
    "            print(\"step: {} distance: {} learning rate: {}\".format(i, current_distance, current_learning_rate))\n",
    "            self.train_one_cycle(data, current_distance, current_learning_rate)\n",
    "            \n",
    "    #labeling - make sure to use normalized data\n",
    "    def label(self, data_with_labels):\n",
    "        #determine average over all outputs in a given node\n",
    "        node_label = [0.0]*len(self.nodes)\n",
    "        node_label_count = [0]*len(self.nodes)\n",
    "        #store average in node_prediction\n",
    "        self.node_prediction = [0.0]*len(self.nodes)\n",
    "        for data_point in data_with_labels:\n",
    "            winner = self.find_winning_node(data_point[1:9])\n",
    "            node_label[winner] += data_point[11]\n",
    "            node_label_count[winner] += 1\n",
    "        for j in range(len(self.nodes)):\n",
    "            if(node_label_count[j] > 0):\n",
    "                self.node_prediction[j] = node_label[j] / node_label_count[j]\n",
    "        print(\"node labels: \")\n",
    "        data = self.node_prediction\n",
    "        heatmap = matplotlib.pyplot.pcolor(numpy.reshape( data, (self.one_side, self.one_side)), cmap=plt.cm.Blues)\n",
    "        matplotlib.pyplot.show()\n",
    "        matplotlib.pyplot.gca().invert_yaxis()\n",
    "            \n",
    "    #testing a single data point\n",
    "    def test_datapoint(self, datapoint_without_labels):\n",
    "        winner = self.find_winning_node(datapoint_without_labels[1:9])\n",
    "        return [winner, datapoint_without_labels[0], self.node_prediction[winner]]\n",
    "    \n",
    "    #testing data set\n",
    "    def test(self, data_without_labels):\n",
    "        return [self.test_datapoint(datapoint) for datapoint in data_without_labels]\n",
    "    \n",
    "    #predicting a single data point\n",
    "    def predict_datapoint(self, datapoint_without_labels):\n",
    "        #the predicted value is the label of the node closest to the input\n",
    "        return self.node_prediction[self.find_winning_node(datapoint_without_labels)]\n",
    "\n",
    "    #predicting data set\n",
    "    def predict(self, data_without_labels):\n",
    "        return [[tuple(datapoint)[0], self.predict_datapoint(tuple(datapoint)[1:9])] for datapoint in data_without_labels]\n",
    "            \n",
    "#create the training & test sets, skipping the header row with [1:]\n",
    "train_dataset = genfromtxt(open('test/train.csv','r'), delimiter=',', dtype='f12')[1:]\n",
    "train = [x[1:9] for x in train_dataset]\n",
    "\n",
    "test_dataset = genfromtxt(open('test/test.csv','r'), delimiter=',', dtype='f12')[1:]\n",
    "test = [x[1:9] for x in test_dataset]\n",
    "\n",
    "train_april_dataset = genfromtxt(open('test/train_april.csv','r'), delimiter=',', dtype='f12')\n",
    "train_10am_dataset = genfromtxt(open('test/train_10am.csv','r'), delimiter=',', dtype='f12')\n",
    "train_6pm_dataset = genfromtxt(open('test/train_6pm.csv','r'), delimiter=',', dtype='f12')\n",
    "\n",
    "#shuffle the training data set to avoid getting stuck in local minima\n",
    "random.shuffle(train)\n",
    "\n",
    "#determine min and max for all training inputs\n",
    "max_inputs = train[0]\n",
    "min_inputs = train[0]\n",
    "\n",
    "for x in train :\n",
    "    max_inputs = maximum( max_inputs, x)\n",
    "    min_inputs = minimum( min_inputs, x)\n",
    "    \n",
    "print(max_inputs)\n",
    "print(min_inputs)\n",
    "\n",
    "#normalize data, assumes non-negativity\n",
    "train /= max_inputs\n",
    "for data_point in train_dataset:\n",
    "    data_point[1:9] /= max_inputs\n",
    "for data_point in test_dataset:\n",
    "    data_point[1:9] /= max_inputs\n",
    "for data_point in train_april_dataset:\n",
    "    data_point[1:9] /= max_inputs\n",
    "for data_point in train_10am_dataset:\n",
    "    data_point[1:9] /= max_inputs\n",
    "for data_point in train_6pm_dataset:\n",
    "    data_point[1:9] /= max_inputs\n",
    "\n",
    "#create the SOM - training data is employed for initializing nodes\n",
    "som = SOM(400, train)\n",
    "\n",
    "#either train the SOM or load the pretrained weights - check size\n",
    "som.load_nodes('nodes.csv')\n",
    "#som.train(train, 100, 6, 0.2)\n",
    "\n",
    "#test categorization power of the SOM by checking distribution of all April data points\n",
    "print(\"labeling April data: \")\n",
    "#som.label(train_april_dataset)\n",
    "\n",
    "#test categorization power of the SOM by checking distribution of all 10am data points\n",
    "print(\"labeling 10am data: \")\n",
    "#som.label(train_10am_dataset)\n",
    "\n",
    "#test categorization power of the SOM by checking distribution of all 6pm data points\n",
    "print(\"labeling 6pm data: \")\n",
    "#som.label(train_6pm_dataset)\n",
    "\n",
    "#label nodes with all data points for prediction\n",
    "print(\"labeling all data: \")\n",
    "som.label(train_dataset)\n",
    "\n",
    "prediction_dataset = genfromtxt(open('test.csv','r'), delimiter=',', dtype='S20,f,f,f,f,f,f,f,f')[1:]\n",
    "\n",
    "#predict on test data for submission\n",
    "predicted = som.predict(prediction_dataset)\n",
    "\n",
    "#save the predictions to the file\n",
    "savetxt('submission.csv', numpy.array(predicted), delimiter=',', fmt =\"%s\", header='datetime,count', comments = '')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Labeling\n",
    "The labeling is reproduced here. Technically, only the labeling with all data is necessary for testing. There must be a bug in my code since the first plot doesn't have the inverted y-axis but an inverted empty plot is drawn at the end of the last cell.\n",
    "\n",
    "#### Quick testing note WITHOUT prediction\n",
    "The labeling is the only 'time expensive' step in this notebook (assuming loading of the weights.) Therefore, for 'quick' testing WITHOUT prediction it will be faster to use train_april_dataset for labeling because it only contains 1/12 of the data. But this will leave the predicted bike rentals at 0.0 for all nodes without April data (see heatmap.)\n",
    "\n",
    "### Testing\n",
    "Wrote an 'additional' predict function because the test function didn't correctly handle the timestamps (I preprocessed the input file with vi.) Now this notebook reads data from 'test.csv', predicts the total number of bike rentals for each input vector, and writes timestamp and prediction to 'submission.csv'. To predict on another file 'test.csv' should be replaced with that file. The results will be in submission.csv.\n",
    "\n",
    "### Results\n",
    "As the 10am and 6pm heatmaps already suggested, there is no strong clustering of the training data by time of day for the suggested self-organizing map. This leads to a more or less random prediction by this self-organizing map. For actual prediction a time series analysis makes more sense. Which could be trained on a similar self-organizing map with sliding averages over the number of bike rentals as additional inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
